{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Generator\n",
    "In this part we generate lattice (graph) and introduce X, Y, Z error using depolarization noisy model, which is more close to real world than the independent model favored by surface code.\n",
    "\n",
    "Here we need to adjust `physical error rate` and `lattice size` to generate different case\n",
    "\n",
    "Beware that lattice size `L` is just the width/height of grid, and L\\*L is not the number of physical qubits. Instead, L\\*L\\*2 will be physical qubit num.\n",
    "\n",
    "To generate `Checking matrix` to fit into `PyMatching` lib, we use special way to translate our surface code into check matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# NOTE: 3x3 toric code, there are 2*N*N = 18 physical qubits\n",
    "#   0    1     2\n",
    "# 3─┼──4──┼──5──┼─\n",
    "#   6     7     8  \n",
    "# 9─┼──10─┼──11─┼─\n",
    "#   12    13    14  \n",
    "# 15┼──16─┼──17─┼─ \n",
    "################\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# Parameters,test number for one set of parameters\n",
    "test_num = 2000\n",
    "\n",
    "# in the article, they do not use depolarized error model, which will cause physical error rate to be 2p(1-p),\n",
    "# instead, they just use imple error rate p.\n",
    "\n",
    "# physical error rate, increasing list\n",
    "p_x = np.arange(0.04,0.04+0.025,0.025/25,dtype=float)\n",
    "p_y = p_x\n",
    "p_z = p_x\n",
    "\n",
    "# Lattice size, treat it as a square lattice\n",
    "sizeX = np.ones(len(p_x),dtype=int)*17\n",
    "sizeY = sizeX\n",
    "num_neighbours = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. firstly let's generate lattice and add error to the qubit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from enum import Enum\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# we need encode an 2D EDGE position to 1D index in the vector\n",
    "# REMEMBER: x and y start from 0 !!!\n",
    "# for toric code, always use sizeX*sizeY*2 physical qubits, sizeY*2 row, each row sizeX qubits\n",
    "def encode_2D_to_1D(x, y, sizeX, sizeY):\n",
    "    #throw error if x or y is out of range\n",
    "    if x < 0 or x >= sizeX:\n",
    "        raise ValueError(\"x is out of range\")\n",
    "    if y < 0 or y >= sizeY*2:\n",
    "        raise ValueError(\"y is out of range\")\n",
    "    return x + y*sizeX\n",
    "\n",
    "def decode_1D_to_2D(index, sizeX, sizeY):\n",
    "    #throw error if index is out of range\n",
    "    if index < 0 or index >= sizeX*sizeY*2:\n",
    "        raise ValueError(\"index is out of range\")\n",
    "    return index%sizeX, index//sizeX\n",
    "\n",
    "def initialize_lattice(sizeX,sizeY):\n",
    "    return np.zeros(sizeX*sizeY*2, dtype=int)\n",
    "\n",
    "random.seed()\n",
    "\n",
    "def introduce_errors(lattice, p_x, p_y, p_z):\n",
    "    #introduce errors to the lattice\n",
    "    error_x = np.zeros(len(lattice),dtype=int)\n",
    "    error_z = np.zeros(len(lattice),dtype=int)\n",
    "    for i in range(len(lattice)):\n",
    "        if random.random() > 1-p_x:\n",
    "            error_x[i] = 1-error_x[i] # flip\n",
    "        elif random.random() > 1-p_y:\n",
    "            error_x[i] = 1-error_x[i]\n",
    "            error_z[i] = 1-error_z[i]\n",
    "        elif random.random() > 1-p_z:\n",
    "            error_x[i] = 0\n",
    "            error_z[i] = 1-error_z[i]\n",
    "    return error_z,error_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use surface/toric code model to detect Z and X error using star and plaquettes stablilisers seperately.\n",
    "\n",
    "We firstly build a check_matrix, which can serve as a parity check matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we set that the left and right are smooth boundary, and the bottom and top are rough boundary.\n",
    "def build_check_mat_surface(sizeX,sizeY):\n",
    "    pass\n",
    "# use toric code, consider periodic boundary condition\n",
    "def build_check_mat_toric(sizeX,sizeY):\n",
    "    #first build Z star stabilizer, only odd row have star\n",
    "    Z_check_matrix = []\n",
    "    for y in range(1,sizeY*2,2):\n",
    "        for x in range(0,sizeX):\n",
    "            Z_stab = np.zeros(sizeX*sizeY*2, dtype=int)\n",
    "            Z_stab[encode_2D_to_1D(x,y,sizeX,sizeY)] = \\\n",
    "            Z_stab[encode_2D_to_1D((x+1)%sizeX,y,sizeX,sizeY)] = \\\n",
    "            Z_stab[encode_2D_to_1D(x,y-1,sizeX,sizeY)] = \\\n",
    "            Z_stab[encode_2D_to_1D(x,(y+1)%(sizeY*2),sizeX,sizeY)] = 1\n",
    "            Z_check_matrix.append(Z_stab)\n",
    "    #then build X plaquetee stabilizer\n",
    "    X_check_matrix = []\n",
    "    for y in range(0,sizeY*2,2):\n",
    "        for x in range(0,sizeX):\n",
    "            X_stab = np.zeros(sizeX*sizeY*2, dtype=int)\n",
    "            X_stab[encode_2D_to_1D((x-1)%sizeX,y,sizeX,sizeY)] = \\\n",
    "            X_stab[encode_2D_to_1D(x,y,sizeX,sizeY)] = \\\n",
    "            X_stab[encode_2D_to_1D(x,(y-1)%(sizeY*2),sizeX,sizeY)] = \\\n",
    "            X_stab[encode_2D_to_1D(x,y+1,sizeX,sizeY)] = 1\n",
    "            X_check_matrix.append(X_stab)\n",
    "    #use sparse matrix to save memory\n",
    "    return csr_matrix(Z_check_matrix), csr_matrix(X_check_matrix)\n",
    "\n",
    "def get_syndrome(error_lattice, check_matrix):\n",
    "    #get the syndrome of the error lattice\n",
    "    return check_matrix.dot(error_lattice) % 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Finally write the syndrome and error lattice to file to finish the generation of testpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_one_test(error_x,error_z, syndrome_X,syndrome_Z ,sizeX):\n",
    "    # turn the error lattice into 2D array, write it to a file\n",
    "    reshape_error_x = error_x.reshape(-1,sizeX)\n",
    "    file_content = {\n",
    "        #error_x and z is for correct answer,\n",
    "        \"error_x\":reshape_error_x,\n",
    "        \"error_z\":error_z.reshape(-1,sizeX),\n",
    "        #syndrome_x and syndrome_z is for the input of the decoder\n",
    "        \"syndrome_x\":syndrome_X.reshape(-1,sizeX),\n",
    "        \"syndrome_z\":syndrome_Z.reshape(-1,sizeX),\n",
    "        \"sizeX\":sizeX,\n",
    "        \"sizeY\":len(reshape_error_x)//2\n",
    "    }\n",
    "    return file_content\n",
    "\n",
    "def write_test_file(content_list,filename):\n",
    "    np.savez(\"../code/data/input/\"+filename, content_list)\n",
    "\n",
    "def pack_one_result(consume_time,correct_x,correct_z):\n",
    "    file_content = {\n",
    "        \"time\": consume_time,\n",
    "        \"correct_x\":correct_x,\n",
    "        \"correct_z\":correct_z,\n",
    "    }\n",
    "    return file_content\n",
    "\n",
    "def write_result_file(content_list,filename):\n",
    "    np.savez(\"../code/data/output/\"+filename, content_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now that we have check matrix, using pymatch to generate result here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now since that check_matrix is here, use pymarching lib to get all the statistic\n",
    "from pymatching import Matching\n",
    "import time\n",
    "\n",
    "def pymatch_solver(syndrome_Z,syndrome_X,z_check_mat,x_check_mat,sizeX):\n",
    "    global num_neighbours\n",
    "    #set up a timer\n",
    "    start_time = time.time()\n",
    "    # get the matching graph\n",
    "    decoder_result_Z = Matching(z_check_mat).decode(syndrome_Z,num_neighbours)\n",
    "    decoder_result_X = Matching(x_check_mat).decode(syndrome_X,num_neighbours)\n",
    "    #different syndrome simply mean different code type, like edged surface, toric.\n",
    "    consume_time = time.time() - start_time\n",
    "    return pack_one_result(consume_time,decoder_result_X.reshape(-1,sizeX)\n",
    "        ,decoder_result_Z.reshape(-1,sizeX))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that original lattice and syndromes both need writing out, because we need to visualize the logical error rate in \"visualizer\" part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Winfred X\\AppData\\Local\\Temp\\ipykernel_20724\\1486137469.py:10: DeprecationWarning: The ``num_neighbours`` argument no longer has any effect in PyMatching v2.0.0 or later, since it introduced an approximation that is no longer relevant or necessary. Providing ``num_neighbours`` as the second positional argument to ``Matching.decode`` will raise an exception in a future version of PyMatching\n",
      "  decoder_result_Z = Matching(z_check_mat).decode(syndrome_Z,num_neighbours)\n",
      "C:\\Users\\Winfred X\\AppData\\Local\\Temp\\ipykernel_20724\\1486137469.py:11: DeprecationWarning: The ``num_neighbours`` argument no longer has any effect in PyMatching v2.0.0 or later, since it introduced an approximation that is no longer relevant or necessary. Providing ``num_neighbours`` as the second positional argument to ``Matching.decode`` will raise an exception in a future version of PyMatching\n",
      "  decoder_result_X = Matching(x_check_mat).decode(syndrome_X,num_neighbours)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ii in range(len(p_x)):\n",
    "    #pack all the test and result into a list\n",
    "    pack_test_list = []\n",
    "    pack_result_list = []\n",
    "    for i in range(test_num):\n",
    "        # Initialize and introduce errors\n",
    "        lattice = initialize_lattice(sizeX[ii], sizeY[ii])\n",
    "        # get check matrix for stabilisers\n",
    "        z_check_mat, x_check_mat = build_check_mat_toric(sizeX[ii],sizeY[ii])\n",
    "        # introduce error\n",
    "        error_z,error_x = introduce_errors(lattice, p_x[ii], p_y[ii], p_z[ii])\n",
    "        # get syndrome\n",
    "        syndrome_Z = get_syndrome(error_z,z_check_mat)\n",
    "        syndrome_X = get_syndrome(error_x,x_check_mat)\n",
    "        #now make the lattice and syndrome into 2D array and save them\n",
    "        pack_test_list.append(pack_one_test(error_x,error_z, syndrome_X,syndrome_Z ,sizeX[ii]))\n",
    "        #now solve the syndrome\n",
    "        pack_result_list.append(pymatch_solver(syndrome_Z,syndrome_X,z_check_mat,x_check_mat,sizeX[ii]))\n",
    "    #write pack list\n",
    "    write_test_file(pack_test_list,f\"test{ii}.npz\")\n",
    "    write_result_file(pack_result_list,f\"result{ii}.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
